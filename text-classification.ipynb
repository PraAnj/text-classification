{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 1.0 ] Import packages and workspase setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "## Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Tools for loading/ evaluation\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import utils\n",
    "\n",
    "## Other modules\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 1.1 ] Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents  =  19997\n",
      "Number of categories =  20\n"
     ]
    }
   ],
   "source": [
    "news20groups = load_files('./20_newsgroup', encoding='latin-1', shuffle = True, random_state=42)\n",
    "print ('Number of documents  = ' , len(news20groups.data))\n",
    "print ('Number of categories = ', len(news20groups.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 1.2 ] Important functions and declarations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scoring metrics array.\n",
    "scoring = {'precision': 'precision_macro',\n",
    "           'recall': 'recall_macro',\n",
    "           'F1_score': 'f1_macro',\n",
    "           'accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "def printScores (scores):\n",
    "    print ('recall = ', np.mean(scores['test_recall']))\n",
    "    print ('precision = ', np.mean(scores['test_precision']))\n",
    "    print ('F1_score = ', np.mean(scores['test_F1_score']))\n",
    "    print ('accuracy = ', np.mean(scores['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.1 ] Bag of words feature using CountVectorizer**\n",
    "\n",
    "SVM with linear kernel (SGDClassifier) is used to clasify which is the last argument to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.9123494949494949\n",
      "precision =  0.9249523597217981\n",
      "F1_score =  0.9096568264778186\n",
      "accuracy =  0.912337468734367\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "scores = cross_validate(text_clf, news20groups.data, news20groups.target, scoring=scoring, cv=10, return_train_score=False)\n",
    "printScores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.2 ] TF-iDF feature using TfidfTransformer (with Naive bayes)**\n",
    "\n",
    "Count of BoW model is used as the first transformer. Second transformer is the Tf-idf and Naive bayes classifier (MultinomialNB) is the last argument to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.88735\n",
      "precision =  0.8882495071171721\n",
      "F1_score =  0.8852631713940566\n",
      "accuracy =  0.8873319409704852\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),])\n",
    "\n",
    "scores = cross_validate(text_clf, news20groups.data, news20groups.target, scoring=scoring, cv=10, return_train_score=False)\n",
    "printScores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.3 ] TF-iDF feature using TfidfTransformer (with SVM)**\n",
    "\n",
    "Use of SGDClassifier (Linear SVM with Stochastic gradient decent optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.9362994949494947\n",
      "precision =  0.936986663073885\n",
      "F1_score =  0.934926206514114\n",
      "accuracy =  0.9362900450225112\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),])\n",
    "\n",
    "scores = cross_validate(text_clf, news20groups.data, news20groups.target, scoring=scoring, cv=10, return_train_score=False)\n",
    "printScores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.4 ] TF-iDF feature using TfidfTransformer (with Random forest)**\n",
    "\n",
    "Random forest classifier with default parameter is used to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.8274984848484849\n",
      "precision =  0.8274553438548822\n",
      "F1_score =  0.8255827077650626\n",
      "accuracy =  0.8274755127563782\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', RandomForestClassifier()),])\n",
    "\n",
    "scores = cross_validate(text_clf, news20groups.data, news20groups.target, scoring=scoring, cv=10, return_train_score=False)\n",
    "printScores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.5 ] Hashing vector feature (with SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.9291494949494948\n",
      "precision =  0.9339017025226699\n",
      "F1_score =  0.9279595188641487\n",
      "accuracy =  0.9291390445222613\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('hash', HashingVectorizer(n_features=2 ** 20)),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),])\n",
    "\n",
    "scores = cross_validate(text_clf, news20groups.data, news20groups.target, scoring=scoring, cv=10, return_train_score=False)\n",
    "printScores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.6 ] Hashing vector feature integrated to TF-Idf (with SVM)**\n",
    "\n",
    "SVM Classifier is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall =  0.936299494949495\n",
      "precision =  0.9369787419537339\n",
      "F1_score =  0.9349424652994628\n",
      "accuracy =  0.9362900700350176\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('hash', HashingVectorizer(n_features=2 ** 20)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),])\n",
    "\n",
    "scores = cross_validate(text_clf, news20groups.data, news20groups.target, scoring=scoring, cv=10, return_train_score=False)\n",
    "printScores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.7 ] Doc2vec model with logistic regressoin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec model training example were taken from following article.\n",
    "# https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(news20groups.data, news20groups.target, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1000447.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 697510.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 661410.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 518163.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 647586.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 714631.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 925970.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 500226.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 476407.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 2653300.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 652762.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 952739.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1176924.12it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1961907.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 991037.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 952815.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1064654.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 769622.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 731567.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 476459.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1279651.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 605899.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1111643.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 542144.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 943002.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 649502.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 612170.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 488070.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1111643.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1250667.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 19997/19997 [00:00<00:00, 1176907.60it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8425\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.76      0.77      0.77       303\n",
      "           comp.graphics       0.78      0.77      0.78       315\n",
      " comp.os.ms-windows.misc       0.85      0.83      0.84       320\n",
      "comp.sys.ibm.pc.hardware       0.84      0.83      0.83       314\n",
      "   comp.sys.mac.hardware       0.87      0.91      0.89       291\n",
      "          comp.windows.x       0.87      0.87      0.87       296\n",
      "            misc.forsale       0.84      0.86      0.85       304\n",
      "               rec.autos       0.90      0.84      0.87       309\n",
      "         rec.motorcycles       0.93      0.91      0.92       285\n",
      "      rec.sport.baseball       0.96      0.97      0.97       299\n",
      "        rec.sport.hockey       0.98      0.97      0.98       311\n",
      "               sci.crypt       0.91      0.89      0.90       286\n",
      "         sci.electronics       0.80      0.82      0.81       272\n",
      "                 sci.med       0.89      0.89      0.89       289\n",
      "               sci.space       0.79      0.86      0.82       300\n",
      "  soc.religion.christian       0.98      0.98      0.98       298\n",
      "      talk.politics.guns       0.83      0.82      0.82       312\n",
      "   talk.politics.mideast       0.79      0.88      0.83       303\n",
      "      talk.politics.misc       0.63      0.65      0.64       285\n",
      "      talk.religion.misc       0.64      0.54      0.59       308\n",
      "\n",
      "               micro avg       0.84      0.84      0.84      6000\n",
      "               macro avg       0.84      0.84      0.84      6000\n",
      "            weighted avg       0.84      0.84      0.84      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=news20groups.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[ Section 2.8 ] Doc2vec model with SVM classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Prageeth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8721666666666666\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.75      0.87      0.81       303\n",
      "           comp.graphics       0.82      0.81      0.82       315\n",
      " comp.os.ms-windows.misc       0.89      0.84      0.87       320\n",
      "comp.sys.ibm.pc.hardware       0.85      0.89      0.87       314\n",
      "   comp.sys.mac.hardware       0.87      0.95      0.91       291\n",
      "          comp.windows.x       0.93      0.92      0.93       296\n",
      "            misc.forsale       0.88      0.84      0.86       304\n",
      "               rec.autos       0.93      0.92      0.92       309\n",
      "         rec.motorcycles       0.96      0.96      0.96       285\n",
      "      rec.sport.baseball       0.96      0.98      0.97       299\n",
      "        rec.sport.hockey       0.94      0.99      0.96       311\n",
      "               sci.crypt       0.90      0.97      0.93       286\n",
      "         sci.electronics       0.88      0.82      0.85       272\n",
      "                 sci.med       0.94      0.90      0.92       289\n",
      "               sci.space       0.90      0.95      0.93       300\n",
      "  soc.religion.christian       0.95      0.98      0.97       298\n",
      "      talk.politics.guns       0.84      0.87      0.85       312\n",
      "   talk.politics.mideast       0.84      0.95      0.89       303\n",
      "      talk.politics.misc       0.64      0.69      0.66       285\n",
      "      talk.religion.misc       0.73      0.36      0.48       308\n",
      "\n",
      "               micro avg       0.87      0.87      0.87      6000\n",
      "               macro avg       0.87      0.87      0.87      6000\n",
      "            weighted avg       0.87      0.87      0.87      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)\n",
    "sgd.fit(train_vectors_dbow, y_train)\n",
    "sgd = sgd.fit(train_vectors_dbow, y_train)\n",
    "y_pred = sgd.predict(test_vectors_dbow)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=news20groups.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
